{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5245e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
   "#why does this notebook not include the outputs? Yikes I will need to fix that\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "import os\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "import pytensor.tensor as tt\n",
    "import arviz\n",
    "import corner\n",
    "\n",
    "from import_templates import prep_scale_templates\n",
    "#from VIRUS_target_prep import from_example_h5file #if you want to import VIRUS data from its h5file\n",
    "from features_to_evaluate import avg_point_feature, avg_point_feature_err, slope_feature, slope_feature_err, photometry_feature\n",
    "from least_squares_fitter import least_squares_fit_function\n",
    "from pymc_fitter import pymc_NUTS_fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4e3c7-1489-4b06-803b-86130065f83d",
   "metadata": {},
   "source": [
    "In this notebook, we use nuts-for-ysos with an example spectrum from VIRUS, provided in a fits file (2MASS_J03285101+3118184.fits). There are some rules you should adhere to, when inputting a YSO spectrum into nuts-for-ysos:\n",
    "1. The spectrum must only occupy wavelengths between 3300A and 10190A\n",
    "2. It needs to have a wavelength array with Δλ of at least 0.3 Angstroms.\n",
    "3. The spectrum must have a separate uncertainty array associated with it.\n",
    "4. You need to know the distance to the YSO (though it can be either with or without uncertainty)\n",
    "\n",
    "In the cell below, we define a few things:\n",
    "\n",
    "1. The name for our YSO (in this case 'test_YSO')\n",
    "2. The wavelength array of our spectrum, called 'def_wave_data'\n",
    "3. The average resolution of our spectrum (so that the Class III template resolution can be matched to it)\n",
    "3. The distance to the YSO in parsecs as:\n",
    "    distance_info = [mean_distance, lower bound , upper bound]\n",
    "but if you don't have upper and lower bounds, you can also just set distance_info to be a scalar number in parsecs.\n",
    "4. The Rv used in the extinction law (Cardelli et al 1989). We set it to 3.1, which is the default in nuts-for-ysos anyways.\n",
    "5. The spectrum array, called YSO\n",
    "6. The spectrum's uncertainty, called YSO_err\n",
    "\n",
    "In the repository we provide some example VIRUS YSO spectra with SNR>15, which are are contained in .fits files. These spectra are the same ones used in Willett et al. (in prep).\n",
    "Refer to the file 'VIRUS_target_prep.py' to see how you can quickly retrieve a VIRUS spectrum from its h5 file. The from_example_h5file() function allow you to toggle whether or not the VIRUS spectrum gets rescaled by its PanSTARRS gmag or is normalized, as was done in Willett et al. (in prep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50fa78a-fb20-4c2a-ba29-ee98b799e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'test_YSO'\n",
    "def_wave_data = np.arange(3470, 5542, 2) #angstroms\n",
    "mean_resolution = 750\n",
    "distance_info = [303.156647,297.884674,307.583466] #parsecs\n",
    "Rv = 3.1\n",
    "\n",
    "data_table = Table.read('example_VIRUS_spectra/2MASS_J03285101+3118184.fits')\n",
    "YSO, YSO_err = data_table['flux (erg/s/cm2)'], data_table['error']\n",
    "#YSO, YSO_err = from_example_h5file(h5filename, h5index) #if you want to import VIRUS data directly from its h5file instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99fc6c-cda0-4354-83c0-9ae9b8f4e49a",
   "metadata": {},
   "source": [
    "Here we will plot the YSO spectrum for which we will attempt to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57501620-80f9-47f2-82fe-8bf197defe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(def_wave_data, YSO)\n",
    "plt.xlim(3500,5500)\n",
    "plt.xlabel('wavelength (A)')\n",
    "plt.ylabel('flux (e-17 erg/s/cm2/A)')\n",
    "plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d4fdd-49ac-422f-9abb-6e21302ca6a3",
   "metadata": {},
   "source": [
    "In the next cell, we create the set of class III YSO template spectra from X-Shooter, that are used to represent the photospheres of accreting YSOs. The set spans from Teff = 2400K to 5770K.\n",
    "The function prep_scale_templates() outputs arrays for the template Teff, luminosity (as in log(L/Lsun)), the wavelength array, and the flux. The purpose of this function is to make the raw X-shooter templates match the resolution of your YSO spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c4b4b-1dd5-4181-8407-068a47ec0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_Teffs, template_lums, def_wave_model, templates_scaled = prep_scale_templates(def_wave_data, mean_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887b912-25bf-44c4-b1f5-dafb6621eeda",
   "metadata": {},
   "source": [
    "In fitting the YSO model to the data, we actually do not fit to the entire spectrum. In brief, this is because the model is not meant to replicate the emission lines in the YSO spectrum, only the continuum. We can choose what 'features' in the spectrum we would like to fit for. By default, nuts-for-ysos uses the features in Table 4 of Willett et al. (in prep).\n",
    "There are three types used by default: \n",
    "1. 'point' is an average value over a small wavelength range (eg. 20A).\n",
    "2. 'slope' is one point subtracted from another.\n",
    "3. 'photometry' is the AB magnitude you obtain by convolving the spectrum with a specified filter (eg. PanSTARRS g, r, or i)\n",
    "\n",
    "These three types each have respective functions that we imported from features_to_evaluate.py. The functions all take a certain input:\n",
    "1. avg_point_feature takes a wavelength array, left_bound, right_bound, and spectrum array\n",
    "2. slope_feature takes a wavelength array, left_bound_y1, right_bound_y1, left_bound_y2, right_bound_y2, and spectrum array. The output is y2-y1.\n",
    "3. photometry_feature takes a wavelength array, a filter array, and spectrum array. \n",
    "\n",
    "In the cell below, we start by defining the PanSTARRRS r ang i filters, read from the provided files 'psr_filter_curve.csv' and 'psi_filter_curve.csv'. We then set the types and bounds for each feature, and give them a name.\n",
    "\n",
    "Finally, we determine the values of these features for our YSO spectrum. \n",
    "Note that for our example, we do not actually calculate the 'photometry' features for the inputted YSO spectrum. Instead, we set the value to just be the official PanSTARRS r and i magnitudes. We *will* calculate 'rmag' and 'imag' for the model. But for the VIRUS data itself, the wavelength array only goes up to 5500A and is therefore not covered by the rmag and imag filters. We conservatively set the uncertainty on rmag and imag to each be 0.2 (see Willett et al. (in prep) for explanation on this)\n",
    "\n",
    "Ultimately, you can choose whatever features you want, as long as you follow the same framework used here. You can customize the types and bounds of the features simply by changing the values in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eaf0af-8a28-4cb1-b43e-624ab6c9e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pan-STARRS filters\n",
    "ps2r_file = Table.read('psr_filter_curve.csv')\n",
    "ps2r_wave=ps2r_file ['wavelength (A)']\n",
    "ps2r_val=ps2r_file ['transmission']\n",
    "ps2r_wave = np.array(ps2r_wave)\n",
    "ps2r_val = np.array(ps2r_val)\n",
    "filtr = np.interp(def_wave_model, ps2r_wave, ps2r_val, left=0.0, right=0.0)\n",
    "ps2i_file = Table.read('psi_filter_curve.csv')\n",
    "ps2i_wave=ps2i_file ['wavelength (A)']\n",
    "ps2i_val=ps2i_file ['transmission']\n",
    "ps2i_wave = np.array(ps2i_wave)\n",
    "ps2i_val = np.array(ps2i_val)\n",
    "filti = np.interp(def_wave_model, ps2i_wave, ps2i_val, left=0.0, right=0.0)\n",
    "\n",
    "feature_types = ['slope', 'point', 'point', 'point', 'slope', 'point', 'point', 'point', 'slope', 'photometry', 'photometry']\n",
    "feature_bounds = [[3504.0, 3524.0, 3580.0, 3600.0], [3580.0, 3620.0], [3850.0, 3870.0], [4000.0, 4030.0], [3980.0, 4020.0, 4770.0, 4820.0], [4590.0, 4624.0], [5090.0, 5130.0], [5460.0, 5490.0], [5060.0, 5100.0, 5390.0, 5424.0], filtr, filti]\n",
    "feature_names = ['balmer_slope', 'balmer_val', 'balmer_val_2', 'purple_val', 'paschen_slope', 'paschen_val', 'optical_val', 'optical_val_2', 'optical_slope_2', 'rmag', 'imag']\n",
    "\n",
    "YSO_spectrum_features = []\n",
    "YSO_spectrum_features_errs = []\n",
    "for f in range(0, len(feature_types)):\n",
    "    if feature_types[f] == 'ratio':\n",
    "        YSO_spectrum_features.append(ratio_feature(def_wave_data, feature_bounds[f][0], feature_bounds[f][1], feature_bounds[f][2], feature_bounds[f][3], YSO))\n",
    "        YSO_spectrum_features_errs.append(ratio_feature_err(def_wave_data, feature_bounds[f][0], feature_bounds[f][1], feature_bounds[f][2], feature_bounds[f][3], YSO, YSO_err))\n",
    "    if feature_types[f] == 'point':\n",
    "        YSO_spectrum_features.append(avg_point_feature(def_wave_data, feature_bounds[f][0], feature_bounds[f][1], YSO))\n",
    "        YSO_spectrum_features_errs.append(avg_point_feature_err(def_wave_data, feature_bounds[f][0], feature_bounds[f][1], YSO, YSO_err))\n",
    "    if feature_types[f] == 'slope':\n",
    "        YSO_spectrum_features.append(slope_feature(def_wave_data, feature_bounds[f][0], feature_bounds[f][1], feature_bounds[f][2], feature_bounds[f][3], YSO))\n",
    "        YSO_spectrum_features_errs.append(slope_feature_err(def_wave_data, feature_bounds[f][0], feature_bounds[f][1], feature_bounds[f][2], feature_bounds[f][3], YSO, YSO_err))\n",
    "    #if feature_types[f] == 'photometry':\n",
    "        #we are not going to be taking photometry from the spectrum itself, instead we use PanSTARRS (see below)\n",
    "\n",
    "#from PanSTARRS data\n",
    "ps_rmag_target = 16.0739\n",
    "ps_imag_target = 14.6527\n",
    "YSO_spectrum_features.append(ps_rmag_target)\n",
    "YSO_spectrum_features_errs.append(0.2)\n",
    "YSO_spectrum_features.append(ps_imag_target)\n",
    "YSO_spectrum_features_errs.append(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc18e6-e7d4-4dae-aa36-31e0d0639cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make a table of the features to summarize for the user\n",
    "feature_formulae = []\n",
    "for i in range(0, len(feature_types)):\n",
    "    if feature_types[i]=='point':\n",
    "        formula = 'avg λ'+str(feature_bounds[i][0])+':'+str(feature_bounds[i][1])\n",
    "    if feature_types[i]=='slope':\n",
    "        formula = 'avg λ'+str(feature_bounds[i][2])+':'+str(feature_bounds[i][3]) + ' - ' + 'avg λ'+str(feature_bounds[i][0])+':'+str(feature_bounds[i][1])\n",
    "    if feature_types[i]=='photometry':\n",
    "        formula = 'filter (eg. PanSTARRS)'\n",
    "    feature_formulae.append(formula)\n",
    "\n",
    "feature_table = Table([feature_names, feature_types, feature_formulae, YSO_spectrum_features, YSO_spectrum_features_errs], names=('Feature Name', 'Type', 'Formula', 'YSO Value', 'YSO uncert'))\n",
    "feature_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bbe15-cb79-4ab1-ac32-cdaad5a73a40",
   "metadata": {},
   "source": [
    "The goal of nuts-for-ysos is to use the NUTS sampler within PyMC. But the sampler requires a starting point. We find our starting point for the parameters using the least_squares_fit_function() as done below. \n",
    "By default, least_squares_fit_function() plots the result of the fit. It's useful to see the plot so that you can note whether the result looks reasonable or whether there might be an issue in your input somewhere. The PyMC portion can take a while to run! So it is better to address issues at this stage. If you want to skip the plot, include plot=False at the end of the least_squares_fit_function() arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616ee65-340e-4bd0-b950-f68ad424f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = least_squares_fit_function(def_wave_data, mean_resolution, YSO, YSO_spectrum_features, YSO_spectrum_features_errs, feature_types, feature_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185fa0d-0979-4de1-b136-d678f2ed549a",
   "metadata": {},
   "source": [
    "In the cell below, we finally carry out the model fitting with PyMC. Once NUTS is initialized, you'll see a progress bar to see how far along the sampling process is. Once the sampling is complete, the PyMC trace (which is, by default, returned as an ArviZ InferenceData object) is stored in a 'NetCDF' file.\n",
    "You can find more information on PyMC here: https://www.pymc.io/welcome.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e773861-1eef-44f5-897e-134a77699b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accept_set = 0.99\n",
    "length = 2000\n",
    "chains = 16\n",
    "cores = 16\n",
    "\n",
    "trace = pymc_NUTS_fitting(def_wave_data, mean_resolution, np.array(YSO_spectrum_features), np.array(YSO_spectrum_features_errs), feature_types, feature_bounds, distance_info, name, np.array(init_params), target_accept_set, length, chains, cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19db92-9e3f-49cc-ad48-00a68b7a6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you need to retrieve the trace from its NetCDF file later:\n",
    "#trace = arviz.from_netcdf(name+'_tracefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca50e1-6bca-4c7c-812f-429a520084ca",
   "metadata": {},
   "source": [
    "The summary() function in ArviZ derives useful results from the trace, such as the averages and standard deviations for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3ea75-0594-4a64-9743-eeb4e37797aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = arviz.summary(trace)\n",
    "print(summary)\n",
    "summaryfile = open(name+ '_summary.txt', 'w')\n",
    "summaryfile.write(str(summary))\n",
    "summaryfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6719b52-ed82-44ec-840e-a8c1b218786b",
   "metadata": {},
   "source": [
    "A useful visualizing plot can also be made directly from the trace, through the ArviZ plot_trace() function. The 'corner' package also lets us easily make corner plots directly from the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51ebfe-0857-46c4-84ea-db7112c0cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_trace(trace, var_names = ['T', 'n_e_log', 'tau_0', 'Kslab_1e6_log', 'Kphot_1e6_log', 'Teff', 'Av', 'L_log_traced', 'Lacc_log_traced'])\n",
    "plt.savefig(name+'_traceplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00ad30-8cff-4a73-85f8-16fb942fc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(trace, var_names = ['T', 'n_e_log', 'tau_0', 'Kslab_1e6_log', 'Kphot_1e6_log', 'Teff', 'Av', 'L_log_traced', 'Lacc_log_traced'], labels = [r'$T_{slab}$', r'$log(n_{e})$', r'$τ_0$', r'$log(K_{slab}$*1e6)', r'$log(K_{phot}$*1e6)', r'$T_{eff}$', r'$A_{V}$', r'$log(L_{*}/L_{\\odot})$', r'$log(L_{acc}/L_{\\odot})$'], label_kwargs={\"fontsize\": 20})\n",
    "plt.savefig(name+'_corner')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bb5b1-5b06-4976-b5d8-7c8402175060",
   "metadata": {},
   "source": [
    "If the trace has a significant level of autocorrelation, we need to thin out the trace to mitigate the autocorrelation (ie. use only every nth value of the trace). To learn more about autocorrelation and other aspects of the trace, see https://pymcmc.readthedocs.io/en/latest/modelchecking.html. To check if thinning=20 is enough for your trace, you can use the plot_autocorr() function in ArviZ. Below we plot only for the first 3 chains, but you should check all of your chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab350cdc-31cf-480b-95b1-673d6d04f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_autocorr(trace.sel(chain=[0,1,2]), var_names= ['T', 'n_e_log', 'tau_0', 'Kslab_1e6_log', 'Kphot_1e6_log', 'Teff', 'Av'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7fe91-f163-42ec-9185-baecb679fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "thinning = 20 #for example, use every 20th sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b323a38-69dc-469b-a4c1-ec46dba5fb48",
   "metadata": {},
   "source": [
    "Finally, we can plot out what the resulting model fit looks like. The rest of the cells in this notebook are dedicated to plotting out the median model fit result for our example YSO. The model written below is the same as in pymc_fitter.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1075a-7cd4-4d7b-9c0a-095c9ce80361",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2.99792458 * (1e10)\n",
    "nu = c*(1e8) / def_wave_model\n",
    "wave_cm = (def_wave_model*(1e-8))\n",
    "diff = def_wave_model[1]-def_wave_model[0]\n",
    "wavelength_spacing_model = diff #angstroms\n",
    "full_wave = wavelength_spacing_model*np.arange((def_wave_data[0]/wavelength_spacing_model-((def_wave_data[0]-500)//wavelength_spacing_model)),(def_wave_data[0]/wavelength_spacing_model-((def_wave_data[0]-25000)//wavelength_spacing_model)))\n",
    "nu_2 = c*(1e8) / full_wave\n",
    "wave_cm_2 = (full_wave*(1e-8))\n",
    "wavelength_micron = full_wave / 10000\n",
    "\n",
    "h = 6.62607004 * (1e-27)\n",
    "k_B = 1.38064852 * (1e-16)\n",
    "nu_0 = 3.28795 * (1e15) #hz -- ionization frequency for hydrogen\n",
    "mH = 1.6735 * (1e-24)\n",
    "me = 9.10938356 * (1e-28)\n",
    "mp = 1.6726219 * (1e-24)\n",
    "Z_i = 1\n",
    "lamb_0 = 1.6419 #photodetachment threshold in microns\n",
    "alpha = 1.439 * (1e4)\n",
    "lambda_0 = 300e-7 #defined by Manara 2013b\n",
    "freq_0 = c/lambda_0\n",
    "\n",
    "#valid 0.182 to 0.3645 um \n",
    "Ans_ff_1 = [518.1021,  473.2636, -482.2089 , 115.5291, 0, 0]\n",
    "Bns_ff_1 = [-734.8667, 1443.4137 , -737.1616,  169.6374, 0, 0]\n",
    "Cns_ff_1 = [1021.1775, -1977.3395,  1096.8827, -245.6490, 0, 0]\n",
    "Dns_ff_1 = [-479.0721, 922.3575, -521.1341, 114.2430, 0, 0]\n",
    "Ens_ff_1 = [93.1373, -178.9275, 101.7963, -21.9972, 0, 0]\n",
    "Fns_ff_1 = [-6.4285, 12.3600, -7.0571,  1.5097, 0, 0]\n",
    "\n",
    "#valid > 0.3645 um \n",
    "Ans_ff_2 = [0, 2483.3460, -3449.8890, 2200.0400, -696.2710, 88.2830]\n",
    "Bns_ff_2 = [0, 285.8270, -1158.3820, 2427.7190, -1841.4000, 444.5170]\n",
    "Cns_ff_2 = [0, -2054.2910, 8746.5230, -13651.1050, 8624.9700, -1863.8640]\n",
    "Dns_ff_2 = [0, 2827.7760, -11485.6320, 16755.5240, -10051.5300, 2095.2880]\n",
    "Ens_ff_2 = [0, -1341.5370, 5303.6090, -7510.4940, 4400.0670, -901.7880]\n",
    "Fns_ff_2 = [0, 208.9520, -812.9390, 1132.7380, -655.0200, 132.9850]\n",
    "\n",
    "Cns_fb = [152.519, 49.534, -118.858, 92.536, -34.194, 4.982] #valid from 0.125 to 1.6419 um\n",
    "\n",
    "T = tt.scalar('T')\n",
    "n_e = tt.scalar('n_e')\n",
    "tau_0 = tt.scalar('tau_0')\n",
    "Kslab = tt.scalar('Kslab')\n",
    "Kphot = tt.scalar('Kphot')\n",
    "Av = tt.scalar('Av')\n",
    "Av_grid_uncert = tt.scalar('Av_grid_uncert')\n",
    "Teff = tt.scalar('Teff')\n",
    "Teff_grid_uncert = tt.scalar('Teff_grid_uncert')\n",
    "\n",
    "templates_scaled_shared = tt.as_tensor(np.array(templates_scaled))\n",
    "template_Teffs_shared = tt.as_tensor(np.array(template_Teffs))\n",
    "template_Teff_right = (tt.switch((template_Teffs_shared > (Teff+Teff_grid_uncert)), template_Teffs_shared, 0))\n",
    "template_Teff_right = tt.min(template_Teff_right[template_Teff_right.nonzero()])\n",
    "template_right = templates_scaled_shared[(tt.eq(template_Teffs_shared, template_Teff_right).nonzero()[0][0])]\n",
    "template_Teff_left = (tt.switch((template_Teffs_shared <= (Teff+Teff_grid_uncert)), template_Teffs_shared, 0))\n",
    "template_Teff_left = tt.max(template_Teff_left[template_Teff_left.nonzero()]) \n",
    "template_left = templates_scaled_shared[(tt.eq(template_Teffs_shared, template_Teff_left).nonzero()[0][0])]\n",
    "rightweight = (Teff+Teff_grid_uncert-template_Teff_left)/(template_Teff_right-template_Teff_left)\n",
    "leftweight = (template_Teff_right-(Teff+Teff_grid_uncert))/(template_Teff_right-template_Teff_left)\n",
    "my_template = tt.switch(tt.eq(template_Teff_left,(Teff+Teff_grid_uncert)),template_left,(leftweight*template_left + rightweight*template_right))\n",
    "photosphere = my_template\n",
    "    \n",
    "B_out_2 = 2*h*(nu_2**3)*(1/((tt.exp((h*nu_2)/(k_B*T)))-1))/(c**2)\n",
    "coeff = (2*h*nu_0*(Z_i**2)) / (k_B*T)\n",
    "m_2 = tt.floor((nu_0*(Z_i**2)/nu_2)**(1/2)+1)\n",
    "frac1_2 = tt.switch(tt.eq(m_2, 1.0), (nu_2/(nu_0 * (Z_i**2))), 0)\n",
    "frac1_2 = frac1_2[frac1_2.nonzero()]\n",
    "frac2_2 = tt.switch(tt.eq(m_2, 2.0), (nu_2/(nu_0 * (Z_i**2))), 0)\n",
    "frac2_2 = frac2_2[frac2_2.nonzero()]\n",
    "frac3_2 = tt.switch(tt.eq(m_2, 3.0), (nu_2/(nu_0 * (Z_i**2))), 0)\n",
    "frac3_2 = frac3_2[frac3_2.nonzero()]\n",
    "frac4_2 = tt.switch(tt.eq(m_2, 4.0), (nu_2/(nu_0 * (Z_i**2))), 0)\n",
    "frac4_2 = frac4_2[frac4_2.nonzero()]\n",
    "frac5_2 = tt.switch(tt.eq(m_2, 5.0), (nu_2/(nu_0 * (Z_i**2))), 0)\n",
    "frac5_2 = frac5_2[frac5_2.nonzero()]\n",
    "frac6_2 = tt.switch(tt.eq(m_2, 6.0), (nu_2/(nu_0 * (Z_i**2))), 0)\n",
    "frac6_2 = frac6_2[frac6_2.nonzero()]\n",
    "y1_2 = tt.zeros(frac1_2.shape)\n",
    "y2_2 = tt.zeros(frac2_2.shape)\n",
    "y3_2 = tt.zeros(frac3_2.shape)\n",
    "y4_2 = tt.zeros(frac4_2.shape)\n",
    "y5_2 = tt.zeros(frac5_2.shape)\n",
    "y6_2 = tt.zeros(frac6_2.shape)\n",
    "for n in range(1, 20):\n",
    "    gn = 1 + (0.1728*(frac1_2**(1/3) - (2*(frac1_2**(-2/3))/(n**2)))) - .0496*(frac1_2**(2/3) - (2*(frac1_2**(-1/3))/((3*(n**2)))) + (2*(frac1_2**(-4/3))/((3*(n**4)))))\n",
    "    exp = (h*nu_0) / ((n**2)*k_B*T)\n",
    "    y1_2 += (n**-3)*(tt.exp(exp))*gn\n",
    "for n in range(2, 20):\n",
    "    gn = 1 + (0.1728*(frac2_2**(1/3) - (2*(frac2_2**(-2/3))/(n**2)))) - .0496*(frac2_2**(2/3) - (2*(frac2_2**(-1/3))/((3*(n**2)))) + (2*(frac2_2**(-4/3))/((3*(n**4)))))\n",
    "    exp = (h*nu_0) / ((n**2)*k_B*T)\n",
    "    y2_2 += (n**-3)*(tt.exp(exp))*gn\n",
    "for n in range(3, 20):\n",
    "    gn = 1 + (0.1728*(frac3_2**(1/3) - (2*(frac3_2**(-2/3))/(n**2)))) - .0496*(frac3_2**(2/3) - (2*(frac3_2**(-1/3))/((3*(n**2)))) + (2*(frac3_2**(-4/3))/((3*(n**4)))))\n",
    "    exp = (h*nu_0) / ((n**2)*k_B*T)\n",
    "    y3_2 += (n**-3)*(tt.exp(exp))*gn    \n",
    "for n in range(4, 20):\n",
    "    gn = 1 + (0.1728*(frac4_2**(1/3) - (2*(frac4_2**(-2/3))/(n**2)))) - .0496*(frac4_2**(2/3) - (2*(frac4_2**(-1/3))/((3*(n**2)))) + (2*(frac4_2**(-4/3))/((3*(n**4)))))\n",
    "    exp = (h*nu_0) / ((n**2)*k_B*T)\n",
    "    y4_2 += (n**-3)*(tt.exp(exp))*gn \n",
    "for n in range(5, 20):\n",
    "    gn = 1 + (0.1728*(frac5_2**(1/3) - (2*(frac5_2**(-2/3))/(n**2)))) - .0496*(frac5_2**(2/3) - (2*(frac5_2**(-1/3))/((3*(n**2)))) + (2*(frac5_2**(-4/3))/((3*(n**4)))))\n",
    "    exp = (h*nu_0) / ((n**2)*k_B*T)\n",
    "    y5_2 += (n**-3)*(tt.exp(exp))*gn \n",
    "for n in range(6, 20):\n",
    "    gn = 1 + (0.1728*(frac6_2**(1/3) - (2*(frac6_2**(-2/3))/(n**2)))) - .0496*(frac6_2**(2/3) - (2*(frac6_2**(-1/3))/((3*(n**2)))) + (2*(frac6_2**(-4/3))/((3*(n**4)))))\n",
    "    exp = (h*nu_0) / ((n**2)*k_B*T)\n",
    "    y6_2 += (n**-3)*(tt.exp(exp))*gn \n",
    "g_fb_out_2=(tt.concatenate((y1_2,y2_2,y3_2,y4_2,y5_2,y6_2)))*coeff\n",
    "g_ff_out_2 = 1 + (0.1728* ((nu_2/(nu_0*(Z_i**2)))**(1/3)) *(1+(2*k_B*T/(h*nu_2)))) - (.0496*((nu_2/(nu_0*(Z_i**2)))**(2/3)) * (1+(2*k_B*T/(3*h*nu_2)) +((4/3)*((k_B*T/(h*nu_2))**2)) ))\n",
    "j_out_2 = 5.44*(1e-39)*(tt.exp((-h*nu_2)/(k_B*T)))*(T**(-1/2)) * (n_e**2) * (g_ff_out_2 + g_fb_out_2)\n",
    "coeff = (2*h*nu_0*(Z_i**2)) / (k_B*T)\n",
    "B_Lslab_out = 2*h*(freq_0**3)*(1/((tt.exp((h*freq_0)/(k_B*T)))-1))/(c**2)\n",
    "g_ff_Lslab_out = 1 + (0.1728* ((freq_0/(nu_0*(Z_i**2)))**(1/3)) *(1+(2*k_B*T/(h*freq_0)))) - (.0496*((freq_0/(nu_0*(Z_i**2)))**(2/3)) * (1+(2*k_B*T/(3*h*freq_0)) +((4/3)*((k_B*T/(h*freq_0))**2)) ))\n",
    "g_fb_Lslab_out = 0\n",
    "for n in range(2, 20):\n",
    "    gn = 1 + (0.1728*((freq_0/(nu_0 * (Z_i**2)))**(1/3) - (2*((freq_0/(nu_0 * (Z_i**2)))**(-2/3))/(n**2)))) - .0496*((freq_0/(nu_0 * (Z_i**2)))**(2/3) - (2*((freq_0/(nu_0 * (Z_i**2)))**(-1/3))/((3*(n**2)))) + (2*((freq_0/(nu_0 * (Z_i**2)))**(-4/3))/((3*(n**4)))))\n",
    "    g_fb_Lslab_out += (n**-3)*(tt.exp((h*nu_0) / ((n**2)*k_B*T)))*gn\n",
    "g_fb_Lslab_out *= coeff \n",
    "j_Lslab_out = 5.44*(1e-39)*(tt.exp((-h*freq_0)/(k_B*T)))*(T**(-1/2)) * (n_e**2) * (g_ff_Lslab_out + g_fb_Lslab_out)\n",
    "Lslab_out = tau_0 * B_Lslab_out / j_Lslab_out\n",
    "tau_H_out_2 = j_out_2 * Lslab_out / B_out_2 \n",
    "lamb_2 = (c/nu_2) *(1e4)\n",
    "lamb_2_alt = tt.switch(lamb_2 < lamb_0, lamb_2, lamb_0)\n",
    "f_out_2 = tt.zeros(len(nu_2))\n",
    "for n in range(0,6):\n",
    "    Cn = Cns_fb[n]\n",
    "    f_out_2+= tt.switch(lamb_2 < lamb_0, Cn * ((1/lamb_2_alt) - (1/lamb_0))**((n)/2),0)\n",
    "sigma_out_2 = tt.switch(lamb_2 < lamb_0, (1e-18)*(lamb_2_alt**3)*(((1/lamb_2_alt) - (1/lamb_0))**(3/2))*(f_out_2),0)\n",
    "k_fb__out_2 = 0.750*(T**(-5/2))*(tt.exp(alpha/(lamb_0*T))) * (1-(tt.exp(-alpha/(lamb_2*T)))) * sigma_out_2\n",
    "lamb1_2 = tt.switch((lamb_2 <= 0.182), lamb_2, 0)\n",
    "lamb1_2 = lamb1_2[lamb1_2.nonzero()]  \n",
    "lamb2_2 = tt.switch((lamb_2 < 0.3645), lamb_2, 0)\n",
    "lamb2_2 = tt.switch((lamb2_2 > 0.182), lamb2_2, 0)\n",
    "lamb2_2 = lamb2_2[lamb2_2.nonzero()] \n",
    "lamb3_2 = tt.switch((lamb_2 >= 0.3645), lamb_2, 0)\n",
    "lamb3_2 = lamb3_2[lamb3_2.nonzero()] \n",
    "y1_2 = tt.zeros(lamb1_2.shape)\n",
    "y2_2 = tt.zeros(lamb2_2.shape)\n",
    "y3_2 = tt.zeros(lamb3_2.shape)\n",
    "for n in range(0,6):\n",
    "    y2_2+= ((5040/T)**((n+1)/2)) * (((lamb2_2**2)*Ans_ff_1[n]) + Bns_ff_1[n] + (Cns_ff_1[n]/lamb2_2) + (Dns_ff_1[n]/(lamb2_2**2)) + (Ens_ff_1[n]/(lamb2_2**3)) + (Fns_ff_1[n]/(lamb2_2**4)))\n",
    "    y3_2+= ((5040/T)**((n+1)/2)) * (((lamb3_2**2)*Ans_ff_2[n]) + Bns_ff_2[n] + (Cns_ff_2[n]/lamb3_2) + (Dns_ff_2[n]/(lamb3_2**2)) + (Ens_ff_2[n]/(lamb3_2**3)) + (Fns_ff_2[n]/(lamb3_2**4)))\n",
    "k_ff__out_2 = (tt.concatenate((y1_2, y2_2, y3_2)))*(1e-29)\n",
    "coeff2 = ((h**3)/((2*math.pi*me*k_B)**(3/2)))\n",
    "n_H_out=0\n",
    "for n in range(1,20):\n",
    "    n_H_out += (n**2)*(tt.exp(h*nu_0/((n**2)*k_B*T)))\n",
    "n_H_out*= coeff2*(T**(-3/2))*(n_e**2)\n",
    "k_H__out_2 = (k_fb__out_2 + k_ff__out_2)*n_e*n_H_out*k_B*T\n",
    "tau_H__out_2 = k_H__out_2 * Lslab_out\n",
    "I_H_out_2 = tau_H_out_2 * B_out_2 * ((1-(tt.exp(-tau_H_out_2)))/tau_H_out_2)\n",
    "I_H__out_2 = tau_H__out_2 * B_out_2 * ((1-(tt.exp(-tau_H__out_2)))/tau_H__out_2)\n",
    "tau_total_2 = tau_H_out_2 + tau_H__out_2\n",
    "beta_tau_total_out_2 = (1-(tt.exp(-tau_total_2)))/tau_total_2\n",
    "I_both_out_2 = tau_total_2 * B_out_2 * beta_tau_total_out_2\n",
    "\n",
    "generate_slab_out_2 = (c*I_both_out_2/((wave_cm_2)**2)) * (1e-8)\n",
    "slab_shortened = generate_slab_out_2[(tt.eq(nu_2, nu[0])).nonzero()[0][0]:((tt.eq(nu_2, nu[-1])).nonzero()[0][0]+int(diff/wavelength_spacing_model)):int(diff/wavelength_spacing_model)]\n",
    "generate_slab = pytensor.function([T, n_e, tau_0], slab_shortened)\n",
    "\n",
    "#reddening\n",
    "wavelength_micron = def_wave_model / 10000\n",
    "wave_inv = (wavelength_micron**-1)\n",
    "x_OPT = wave_inv-1.82\n",
    "a_OPT = 1 + (0.17699*x_OPT) - (0.50447*(x_OPT**2)) - (0.02427*(x_OPT**3)) + (0.72085*(x_OPT**4)) + (0.01979*(x_OPT**5)) - (0.77530*(x_OPT**6)) + (.32999*(x_OPT**7))\n",
    "b_OPT = (1.41338*x_OPT) + (2.28305*(x_OPT**2)) + (1.07233*(x_OPT**3)) - (5.38434*(x_OPT**4)) - (0.62251*(x_OPT**5)) + (5.30260*(x_OPT**6)) - (2.09002*(x_OPT**7))\n",
    "z_OPT = a_OPT + (b_OPT/Rv)\n",
    "x_IR = wave_inv\n",
    "a_IR = 0.574*(x_IR**1.61)\n",
    "b_IR = -0.527*(x_IR**1.61)\n",
    "z_IR = a_IR + (b_IR/Rv)\n",
    "A_specific  = (Av)* tt.switch(((wavelength_micron**-1) >= 1.1), z_OPT, z_IR)\n",
    "A_specific_2  = (Av+Av_grid_uncert)* tt.switch(((wavelength_micron**-1) >= 1.1), z_OPT, z_IR)   \n",
    "reddened_slab = (slab_shortened * (10 ** (-0.4 * A_specific_2)))\n",
    "reddened_photosphere = (photosphere * (10 ** (-0.4 * A_specific)))\n",
    "\n",
    "model = reddened_slab*Kslab + reddened_photosphere*Kphot\n",
    "model_creation = pytensor.function([T, n_e, tau_0, Kslab, Kphot, Av, Av_grid_uncert, Teff, Teff_grid_uncert], [reddened_slab*Kslab, reddened_photosphere*Kphot, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f40e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_array = trace.posterior['T'].values[::thinning][0]\n",
    "n_e_log_array = trace.posterior['n_e_log'].values[::thinning][0]\n",
    "tau_0_array = trace.posterior['tau_0'].values[::thinning][0]\n",
    "Kslab_1e6_array = trace.posterior['Kslab_1e6'].values[::thinning][0]\n",
    "Kphot_1e6_array = trace.posterior['Kphot_1e6'].values[::thinning][0]\n",
    "Av_array = trace.posterior['Av'].values[::thinning][0]\n",
    "Av_grid_uncert_array = trace.posterior['Av_grid_uncert'].values[::thinning][0]\n",
    "Teff_array = trace.posterior['Teff'].values[::thinning][0]\n",
    "Teff_grid_uncert_array = trace.posterior['Teff_grid_uncert'].values[::thinning][0]\n",
    "Lacc_log_array = trace.posterior['Lacc_log_traced'].values[::thinning][0]\n",
    "L_log_array = trace.posterior['L_log_traced'].values[::thinning][0]\n",
    "distance_array = trace.posterior['distance'].values[::thinning][0]\n",
    "\n",
    "model_stack = []\n",
    "model_slab_stack = []\n",
    "model_phot_stack = []\n",
    "for x in range(0, len(T_array)):\n",
    "    T_current = T_array[x]\n",
    "    n_e_current = 10**(n_e_log_array[x])\n",
    "    tau_0_current = tau_0_array[x]\n",
    "    Kslab_current = Kslab_1e6_array[x]/1e6\n",
    "    Kphot_current = Kphot_1e6_array[x]/1e6\n",
    "    Av_current = Av_array[x]\n",
    "    Av_grid_uncert_current = Av_grid_uncert_array[x]\n",
    "    Teff_current = Teff_array[x]\n",
    "    Teff_grid_uncert_current = Teff_grid_uncert_array[x]\n",
    "    model_current = model_creation(T_current, n_e_current, tau_0_current, Kslab_current, Kphot_current, Av_current, Av_grid_uncert_current, Teff_current, Teff_grid_uncert_current)\n",
    "    model_stack.append(model_current[2])\n",
    "    model_slab_stack.append(model_current[0])\n",
    "    model_phot_stack.append(model_current[1])\n",
    "model_stack = np.array(model_stack)\n",
    "model_slab_stack = np.array(model_slab_stack)\n",
    "model_phot_stack = np.array(model_phot_stack)\n",
    "medians = []\n",
    "medians_slab = []\n",
    "medians_phot = []\n",
    "for w in range(0, len(def_wave_model)):\n",
    "    sliced = model_stack[:,w]\n",
    "    sliced_slab = model_slab_stack[:,w]\n",
    "    sliced_phot = model_phot_stack[:,w]\n",
    "    medians.append(np.median(sliced))\n",
    "    medians_slab.append(np.median(sliced_slab))\n",
    "    medians_phot.append(np.median(sliced_phot))\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(def_wave_model, medians, c = 'blue', label = 'total model')\n",
    "ax.plot(def_wave_model, medians_slab, c = 'black', label = 'slab model')\n",
    "ax.plot(def_wave_model, medians_phot, c = 'green', label = 'photospheric template')\n",
    "ax.plot(def_wave_data, YSO, c = 'red', alpha = 0.5, label = 'YSO spectrum')\n",
    "ax.set_xlim(def_wave_data[0], def_wave_data[-1])\n",
    "ax.set_ylim(0, 1*np.max(YSO))\n",
    "ax.legend()\n",
    "ax.set_xlabel('wavelength (A)')\n",
    "ax.set_ylabel('flux (e-17 erg/s/cm2/A)')\n",
    "ax.set_title(name+' median model fit result')\n",
    "fig.savefig(name+ '_median_model_plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1373cb2-b64d-427b-b3f7-0a696d7f03cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
